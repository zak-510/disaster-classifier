version: '3.8'

services:
  train:
    build:
      context: .
      dockerfile: docker/Dockerfile
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - WANDB_API_KEY=${WANDB_API_KEY}
    volumes:
      - ./Data:/app/Data
      - ./output:/app/output
      - ./configs:/app/configs
    command: python3 run_training.py --config configs/train.yaml

  inference:
    build:
      context: .
      dockerfile: docker/Dockerfile
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ./Data:/app/Data
      - ./output:/app/output
      - ./configs:/app/configs
    command: python3 run_inference.py --config configs/inference.yaml

  tensorboard:
    image: tensorflow/tensorflow:latest
    ports:
      - "6006:6006"
    volumes:
      - ./output:/logs
    command: tensorboard --logdir /logs --host 0.0.0.0

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    ports:
      - "5000:5000"
    volumes:
      - ./output/mlflow:/mlflow
    environment:
      - MLFLOW_TRACKING_URI=sqlite:///mlflow/mlflow.db
    command: mlflow server --host 0.0.0.0 